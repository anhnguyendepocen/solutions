---
title: 'ARM: Chapter 6'
output: html_document
---

```{r arm06-pre, echo = F, message = F}
knitr::opts_chunk$set(
  cache = T,
  cache.path = 'arm_cache/',
  fig.path = 'arm_fig/',
  message = F,
  warning = F
  )
library(arm)
load_tidy()

# arm link
arm_url <- 'http://stat.columbia.edu/~gelman/arm/examples/'
```

### Question 1

Import the data:

```{r arm06-q01_}
dat <- read_stata(str_c(arm_url, 'risky.behavior/risky_behaviors.dta'))

# prep data
dat %<>% mutate_at(vars(fupacts, bupacts), as.integer)
dat %<>% filter(bupacts != 0)
```


#### (a)

```{r arm06-q01a}
rega <- glm(
  fupacts ~ couples + women_alone, 
  data = dat,
  family = poisson(link = 'log'),
  offset = log(bupacts)
  )
summary(rega)

fu_hat <- predict(rega, type = 'response')
z <- (dat$fupacts - fu_hat) / sqrt(fu_hat)
pchisq(sum(fu_hat ^ 2), 420 - 3)
```

Based on the reduction in deviance, the model does help explain the reduction in ``number of unprotected sex acts."  However, the overdispersion factor is `r sum(z ^ 2) / 417` which is huge.

#### (b)

```{r arm06-q01b}
regb <- glm(
  fupacts ~ couples + women_alone + sex + bs_hiv, 
  data = dat,
  family = poisson(link = 'log'),
  offset = log(bupacts)
  )
summary(regb)

fu_hat <- predict(regb, type = 'response')
z <- (dat$fupacts - fu_hat) / sqrt(fu_hat)
pchisq(sum(z ^ 2), 420 - 4)
```

Presumably, inclusion of pre-treatment measure of the outcome means adding `bupacts` as an offset.  Adding baseline HIV status does not affect the previous coefficients.  Furthermore, the coefficient on HIV status seems plausible and is statistically significant.  However, the over-dispersion factor is `r sum(z ^ 2) / 416` which is huge.

#### (c)

```{r arm06-q01c}
regc <- glm(
  fupacts ~ couples + women_alone + sex + bs_hiv, 
  data = dat,
  family = quasipoisson(link = 'log'),
  offset = log(bupacts)
  )
summary(regc)
```

The intervention is justified and the results (with regard to treatment) appear robust.

#### (d)

If responses from both the man and the woman in a couple are being included then this is a problem since these observations will be correlated and not i.i.d.

### Question 2

Import the data and estimate the model given by:
$$
z_{i} = X_i \beta  + \epsilon_{i}
$$
$$
y_{i} = \begin{cases} 
D &\text{ if } z_{i} \lt c_{D|I} \\ 
I &\text{ if } z_{i} \in (c_{D|I}, c_{I|R}) \\ 
R &\text{ if } z_{i} \gt c_{I|R}
\end{cases}
$$

```{r arm06-q02}
dat <- read_stata(str_c(arm_url, 'nes/nes5200_processed_voters_realideo.dta'))

# partyid3 (1 = Democrat, 2 = Independent, 3 = Republican, 4 = Apolitical)
# ideo (1 = liberal 3 = moderate, 5 = conservative)
# educ3 (1 = no high school... 4 = college graduate)

reg <- polr(
  factor(partyid3) ~ income + female + white + black + educ3 + ideo,
  data = filter(dat, partyid3 != 9)
  )
```

#### (a)

```{r arm06-q02a}
summary(reg)

exp_fun <- function(x, c_di, c_ir) {
  p1 <- invlogit(c_di - x)
  p2 <- invlogit(c_ir - x)
  p1 + 2 * (p2 - p1) + 3 * (1 - p2)
}

pdat <- tibble(
  partyid3 = as.numeric(model.frame(reg)[, 1]),
  lpred = as.numeric(as.matrix(model.frame(reg)[, 2:7]) %*% reg$coefficients)
)

p <- ggplot(pdat) +
  geom_jitter(aes(lpred, partyid3), alpha = 0.5) +
  geom_segment(
    x = reg$zeta[1], xend = reg$zeta[1],
    y = 1, yend = 2,
    col = 'green', 
    size = 1
    ) +
  geom_segment(
    x = reg$zeta[2], xend = reg$zeta[2],
    y = 2, yend = 3,
    col = 'yellow', 
    size = 1
    ) +
  stat_function(
    fun = exp_fun,
    args = list(c_di = reg$zeta[1], c_ir = reg$zeta[2]),
    col = 'red',
    size = 1
  ) +
  labs(x = 'linear predictor', y = 'party id')
p
```

#### (b)

Skip

#### (c)

The variance of an individual observation is:
$$
\sigma^2 = p_D + 4 p_I + 9 p_R - \left( p_D + 2 p_I + 3 p_R \right)^2
$$
so that the standard error for a sample of size $n$ is:
$$
s = \sqrt{\frac{\sigma}{n}}
$$

```{r arm06-q02c}
pdat <- cbind(pdat, data.frame(predict(reg, type = 'probs')))
names(pdat)[3:5] <- c('probD', 'probI', 'probR')
pdat %<>% 
  mutate(
    pred = probD + 2 * probI + 3 * probR,
    resid = partyid3 - pred
    )

bins <- quantile(pdat$pred, probs = seq(0, 1, 0.02), na.rm = T)

pdat <- pdat %>%
  mutate(
    pred_bin = cut(pred, bins, include.lowest = T)
  ) %>%
  group_by(pred_bin) %>%
  mutate_at(vars(contains('prob'), pred, resid), mean, na.rm = T) %>%
  ungroup()

var_fun <- function(p1, p2, p3) {
  (p1 + 4 * p2 + 9 * p3) - (p1 + 2 * p2 + 3 * p3) ^ 2
}

pdat_bin <- pdat %>%
  count(probD, probI, probR, pred, resid) %>%
  mutate(
    lower = -2 * sqrt(var_fun(probD, probI, probR) / n),
    upper =  2 * sqrt(var_fun(probD, probI, probR) / n)
  )

p <- ggplot(pdat_bin) +
  geom_point(aes(pred, resid)) +
  geom_line(aes(pred, lower)) +
  geom_line(aes(pred, upper))
p

table(abs(pdat_bin$resid) < pdat_bin$upper)
```

### Question 3

```{r arm06-q03_}
dat_92 <- dat %>% 
  filter(year == 1992) %>%
  mutate(
    presvote = replace(presvote_2party, presvote_2party != 2, 0),
    presvote = presvote / 2
  )

regp <- glm(
  presvote ~ income + female + white + educ3 + partyid7,
  family = binomial(link = 'probit'),
  data = dat_92
  )

regl <- glm(
  presvote ~ income + female + white + educ3 + partyid7,
  family = binomial(link = 'logit'),
  data = dat_92
  )

# values should be close to one
regl$coefficients / (regp$coefficients * 1.6)
```

### Question 4

Skip

### Question 5

The Tobit model is given by:
$$
y_i^* = X_i \beta + \epsilon_i
$$
$$
y_i =
\begin{cases}
  y_i^* &\text{ if } y_i^* > 0 \\
  0     &\text{ if } y_i^* \leq 0
\end{cases}
$$
where $y_i$ corresponds to individual $i$'s post-treatment earnings.

```{r arm06-q05_1}
dat <- read_stata(str_c(arm_url, 'lalonde/NSW.dw.obs.dta'))
qplot(dat$re78, bins = 100)
```

From the plot, it is apparent the data is truncated from the left and from the right.

```{r arm06-q05_2}
library(VGAM)

ll <- 0
ul <- count(dat, re78) %>% 
  arrange(desc(n)) %>%
  use_series(re78) %>%
  magrittr::extract(1)

reg <- vglm(
  re78 ~ age + educ + black + married + hisp + educ_cat4 + treat,
  family = tobit(Lower = ll, Upper = ul),
  data = dat
)
summary(reg)
```

### Question 6

Import the data:

```{r arm06-q06_}
# 1986
dat86 <- read.table(str_c(arm_url, 'congress/cong3/1986.asc'))
names(dat86) <- c('icpsr', 'district', 'incumb', 'dem', 'rep')
dat86 %<>% mutate(dshare = dem / (dem + rep))

# 1988
dat88 <- read.table(str_c(arm_url, 'congress/cong3/1988.asc'))
names(dat88) <- c('icpsr', 'district', 'incumb', 'dem', 'rep')
dat88 %<>% mutate(dshare = dem / (dem + rep))

# join
dat <- left_join(
  dat86, dat88,
  by = c('icpsr', 'district'), 
  suffix = c('86', '88')
  )

# contested
dat %<>% 
  filter(dshare86 > 0.1 & dshare86 < 0.9) %>%
  filter(dshare88 > 0.1 & dshare88 < 0.9)

# bad elections
dat %<>% filter(incumb86 != -9 & incumb88 != -9)

# flips
dat %<>% mutate(
  flip = if_else(dshare86 < 0.5 & dshare88 > 0.5, 1, 0),
  flip = if_else(dshare86 > 0.5 & dshare88 < 0.5, 1, 0)
  )
```

#### (a)

```{r arm06-q06a}
rega <- lm(dshare88 ~ dshare86 + incumb88, data = dat)
summary(rega)
ba <- rega$coefficients
```

#### (b)

```{r arm06-q06b}
library(hett)

regb <- tlm(dshare88 ~ dshare86 + incumb88, data = dat)
summary(regb)
bb <- regb$loc.fit$coefficients
```

```{r arm06-q06c}
# plot
p <- ggplot(dat) +
  geom_point(
    data = select(dat, dshare86, dshare88),
    aes(dshare86, dshare88),
    col = 'grey'
    ) +
  geom_point(aes(dshare86, dshare88, col = factor(incumb88)), alpha = 0.7) +
  scale_color_manual(
    name = 'incumbent',
    labels = c('rep', 'none', 'dem'),
    values = c('red', 'black', 'blue')
    ) +
  geom_abline(
    aes(intercept = ba[1] + ba[3], slope = ba[2]),
    col = 'blue',
    data = filter(dat, incumb88 == 1)
    ) +
  geom_abline(
    aes(intercept = ba[1] - ba[3], slope = ba[2]),
    col = 'red',
    data = filter(dat, incumb88 == -1)
    ) +
  geom_abline(
    aes(intercept = bb[1] + bb[3], slope = bb[2]),
    linetype = 3,
    col = 'blue',
    data = filter(dat, incumb88 == 1)
    ) +
  geom_abline(
    aes(intercept = bb[1] - bb[3], slope = bb[2]),
    linetype = 3,
    col = 'red',
    data = filter(dat, incumb88 == -1)
    ) +
  geom_abline(
    aes(intercept = ba[1], slope = ba[2]),
    col = 'black',
    data = filter(dat, incumb88 == 0)
    ) +
  geom_abline(
    aes(intercept = bb[1], slope = bb[2]),
    linetype = 3,
    col = 'black',
    data = filter(dat, incumb88 == 0)
    ) +
  labs(x = 'dem share 1986', y = 'dem share 1988') +
  facet_grid(~incumb88)
p
```

#### (c)

The models have similar coefficients although `tlm()` seems to account better for the outliers in some of the elections where incumbents lost.

### Question 7

#### (a)

```{r arm06-q07a}
dat %<>% mutate(
  doutcome = if_else(dshare88 > 0.5, 1, 0)
  )

regl <- glm(
  doutcome ~ dshare86 + incumb88,
  family = binomial(link = 'logit'),
  data = dat
  )
summary(regl)
```

#### (b)

The model is given:
$$
P(\text{Democrat wins}) = P(X_i \beta + \epsilon_i > 0)
$$
where:
$$
\epsilon_i \sim t_\nu \left( 0, \frac{\nu - 2}{\nu} \right)
$$
which is estimated using maximum likelihood and the EM-type algorithm taken from [here](http://www.stat.purdue.edu/~chuanhai/teaching/Stat598A/robit.pdf):
```{r arm06-q07b}
robit_em <- function(par, y, X, tol = 1E-5, maxiter = 1000) {
  
  # robit likelihood
  rll <- function(nu, b, y, X) {
    ll <- y * log(pt(X %*% b, nu)) + (1 - y) * log(1 - pt(X %*% b, nu))
    -sum(ll[is.finite(ll)])
  }
  
  # inits
  n  <- length(y)
  b  <- par$beta
  nu <- par$nu
  it <- 0
  ll <- rll(nu, b, y, X)
  conv = F
    
  while ((!conv) & (it < maxiter)) {
    
    # e step - compute sufficient statistics
    tau_numer <- y - (2 * y - 1) * pt(-(1 + 2 / nu) ^ 0.5 * X %*% b, nu + 2)
    tau_denom <- y - (2 * y - 1) * pt(-X %*% b, nu)
    tau <- tau_numer / tau_denom
    z <- X %*% b + (2 * y - 1) * dt(X %*% b, nu) / tau_numer
    S_txx <- Reduce('+', map(1:n, ~tau[.x] * X[.x, ] %*% t(X[.x, ])))
    S_txz <- Reduce('+', map(1:n, ~tau[.x] * X[.x, ] * z[.x]))
    
    # m step 1 - update beta
    b <- solve(S_txx) %*% S_txz
    
    # m step 2 - search for nu
    m <- 'Brent'
    l <- 2
    u <- 1E9
    opt <- optim(nu, rll, b = b, y = y, X = X, method = m, lower = l, upper = u)
    nu <- opt$par
    
    # check convergence
    conv <- abs(opt$value - ll) < tol
    ll <- opt$value
    
    # increase step
    it <- it + 1
    
  } # end while loop
  
  # exit information
  if (it == maxiter) {
    exit <- 'maxiter reached'
  } else {
    exit <- str_c('Flag: ', opt$convergence, ', Iterations: ', it)
  }
  
  return(
    list(
      coefficents = t(b), 
      nu = nu, 
      logLik = -ll[length(ll)],
      exit = exit
    )
  )
}

par0 <- list(beta = regl$coefficients, nu = 7)
y <- model.frame(regl)[, 1]
X <- cbind(1, model.frame(regl)[, -1])
X %<>% as.matrix()
colnames(X)[1] <- '(Intercept)'
regr <- robit_em(par0, y, X)
print(regr)
```

#### (c)

Given the above, it would appear a standard probit model would work best in this case (i.e. $\nu \rightarrow \infty$).

### Question 8

Skip

### Question 9

Skip

### Question 10

#### (a)

Voter $i$'s ideal point is given by:
$$
\theta_i = X_i \beta + \epsilon_i
$$
with the voter's utility for candidates $A$ and $B$ given by:
$$
\begin{align}
u_{iA} &= || \theta_i - \theta_A || ^ 2 = \theta_i ^ 2 - \theta_i \theta_A + \theta_A ^ 2 \\
u_{iB} &= || \theta_i - \theta_B || ^ 2 = \theta_i ^ 2 - \theta_i \theta_B + \theta_B ^ 2
\end{align}
$$

#### (b)

The voter will choose candidate $A$ if:
$$
u_{iA} > u_{iB} \iff \theta_A ^ 2 - \theta_B ^ 2 + (\theta_B - \theta_A) \theta_i > 0
$$
or equivalently:
$$
-\epsilon_i < \frac{(\theta_A ^ 2 - \theta_B ^ 2)}{(\theta_B - \theta_A)} + X_i \beta
$$
Relabeling and using the distributional assumption for $\epsilon_i$ imply:
$$
P(\text{voter i chooses A}) = \Phi(\alpha + X_i \beta)
$$
where $\Phi(\cdot)$ is the CDF for a standard normal.

### Question 11

Skip